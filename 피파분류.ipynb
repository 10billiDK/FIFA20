{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_df = pd.read_csv(\"players_20.csv\",header=0)\n",
    "data_df.head(3)\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "def format_features(df):\n",
    "    features = ['team_position']\n",
    "    for feature in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "data_df = data_df.dropna(subset=['pace'])\n",
    "data_df = data_df.dropna(subset=['team_position'])\n",
    "positionsub = data_df[data_df['team_position']=='SUB'].index\n",
    "data_df = data_df.drop(positionsub,inplace=False)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "x_data = data_df[['preferred_foot','weak_foot','skill_moves','height_cm','weight_kg',\"attacking_crossing\",'attacking_finishing','attacking_heading_accuracy','attacking_short_passing','attacking_volleys','skill_dribbling','skill_curve','skill_fk_accuracy','skill_long_passing','skill_ball_control','movement_acceleration','movement_sprint_speed','movement_agility','movement_reactions','movement_balance','power_shot_power','power_jumping','power_stamina','power_strength','power_long_shots','mentality_aggression','mentality_interceptions','mentality_vision','mentality_penalties','mentality_composure','defending_marking','defending_standing_tackle','defending_sliding_tackle']]\n",
    "y_data = data_df[['team_position']]\n",
    "print(y_data)\n",
    "y_data = format_features(y_data)\n",
    "\n",
    "feature = ['preferred_foot']\n",
    "le=preprocessing.LabelEncoder()\n",
    "le=le.fit(x_data[feature])\n",
    "x_data[feature] = le.transform(x_data[feature])\n",
    "\n",
    "\n",
    "# **VotingClassifier로 개별모델은 로지스틱 회귀와 KNN을 보팅방식으로 결합하고 성능 비교**\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, \n",
    "                                                    test_size=0.2 , random_state= 156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))\n",
    "\n",
    "\n",
    "# **학습/테스트 데이터로 분리하고 랜덤 포레스트로 학습/예측/평가**\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))\n",
    "\n",
    "\n",
    "# **GridSearchCV 로 교차검증 및 하이퍼 파라미터 튜닝**\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[300],\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=5, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n",
    "\n",
    "\n",
    "# **튜닝된 하이퍼 파라미터로 재 학습 및 예측/평가**\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "rf_clf1 = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8,                                  min_samples_split=8, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "\n",
    "# **개별 feature들의 중요도 시각화**\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
    "                 eval_set=evals, verbose=True)\n",
    "lgbm_preds = lgbm_wrapper.predict(X_test)\n",
    "lgbm_accuracy = accuracy_score(y_test, lgbm_preds)\n",
    "print('LightGBM 정확도: {0:.4f}'.format(lgbm_accuracy))\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred,average='weighted')\n",
    "    recall = recall_score(y_test , pred,average='weighted')\n",
    "    f1 = f1_score(y_test,pred,average='weighted')\n",
    "    ##roc_auc = roc_auc_score(y_test, pred,average='micro',multi_class='ovo')\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "get_clf_eval(y_test, lgbm_preds)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# plot_importance( )를 이용하여 feature 중요도 시각화\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "plot_importance(lgbm_wrapper, ax=ax)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "y_test\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=8)\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=500,random_state=0)\n",
    "\n",
    "# 최종 Stacking 모델을 위한 Classifier생성. \n",
    "lr_final = LogisticRegression()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('gbm 정확도 : {0:.4f}'.format(accuracy_score(y_test,gb_pred)))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "pred = np.array([knn_pred, rf_pred,lgbm_preds])\n",
    "print(pred.shape)\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. \n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=800)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "lgbm_wrapper.fit(pred, y_test,verbose=True)\n",
    "lgbm_preds = lgbm_wrapper.predict(pred)\n",
    "lgbm_accuracy = accuracy_score(y_test, lgbm_preds)\n",
    "print('최종 정확도: {0:.4f}'.format(lgbm_accuracy))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "get_clf_eval(y_test, lgbm_preds)\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "X_train_arr = np.array(X_train)\n",
    "y_train_arr = np.array(y_train)\n",
    "X_test_arr = np.array(X_test)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train_arr, y_train_arr, X_test_arr, 10)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train_arr, y_train_arr, X_test_arr, 10)\n",
    "gb_train, gb_test = get_stacking_base_datasets(gb_clf, X_train_arr, y_train_arr, X_test_arr,  10)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "Stack_final_X_train = np.concatenate((knn_train, rf_train,gb_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test,gb_test), axis=1)\n",
    "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
    "      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=800)\n",
    "lgbm_wrapper.fit(Stack_final_X_train, y_train,verbose=True)\n",
    "lgbm_preds = lgbm_wrapper.predict(Stack_final_X_test)\n",
    "lgbm_accuracy = accuracy_score(y_test, lgbm_preds)\n",
    "print('최종 정확도: {0:.4f}'.format(lgbm_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
